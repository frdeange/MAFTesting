# Azure AI Foundry Configuration
# Copy this file to .env and fill in your actual values

# Azure AI Foundry Project Endpoint
# Find this in Azure AI Foundry portal -> Your Project -> Overview
# Example: https://your-project-name.services.ai.azure.com
AZURE_FOUNDRY_PROJECT_ENDPOINT=https://your-project-name.services.ai.azure.com

# Model Deployment ID
# The name of your deployed model in Azure AI Foundry
# Common examples: gpt-4, gpt-4.1, gpt-4o, gpt-35-turbo
AZURE_FOUNDRY_PROJECT_MODEL_ID=gpt-4.1

# Application Insights Connection String (Optional but recommended)
# Find this in Azure Portal -> Your Application Insights resource -> Overview -> Connection String
# Example: InstrumentationKey=12345678-1234-1234-1234-123456789abc;IngestionEndpoint=https://...
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key-here;IngestionEndpoint=https://your-region.applicationinsights.azure.com/

# OpenTelemetry Exporters Configuration
# Set to 'none' to disable OTLP exporters (recommended to avoid localhost:4317 connection attempts)
OTEL_TRACES_EXPORTER=none
OTEL_METRICS_EXPORTER=none
OTEL_LOGS_EXPORTER=none

# Optional: Logging Level
# Uncomment to enable debug logging
# AZURE_LOG_LEVEL=DEBUG

# Optional: Custom Azure Configuration
# Uncomment if you need to override default Azure settings
# AZURE_TENANT_ID=your-tenant-id
# AZURE_SUBSCRIPTION_ID=your-subscription-id
